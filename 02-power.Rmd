# 2. Statistical Power and Sample Size (Week 3)

This is an edit!


```{r, message=FALSE, warning=FALSE}
# load packages
library(tidyverse)
library(haven)
library(apaTables)
source("data/apafunction.R") #for cool APA-style tables

#load data
nysp_vouchers <- read_dta("data/methods_matter/ch4_nyvoucher.dta")
```


## Effect Size for T-Test

### T-Test Results

```{r}
mm4_t <- t.test(nysp_vouchers$post_ach ~ nysp_vouchers$voucher, var.equal = T)
```
```{r echo=FALSE}
broom::tidy(mm4_t) %>%
  mutate(across(is.numeric, round, 3),
         `std. err` = mm4_t[["stderr"]]) %>%
  rename("no voucher" = estimate1,
         "voucher" = estimate2) %>%
  select(1:4, 6,7,10) %>%
  apa("T-Test Results")
```

### Cohen's *d* effect size for t-test

Using the `effectsize` package:

```{r message=FALSE, warning=FALSE}
library(effectsize)

# use cohens_d() from effectsize
cohens_d(nysp_vouchers$post_ach, as.factor(nysp_vouchers$voucher)) %>%
  # format into an APA table
  mutate(across(is.numeric, round, 3)) %>%  #round
  mutate("95% CI" = paste0("[", CI_low, ", ", CI_high, "]")) %>%   # combine
  select(Cohens_d, `95% CI`) %>%  # drop columns
  rename("Cohen's d"= Cohens_d) %>%   # rename
  apa("Effect size for t-test")
```

> **Interpretation**
> 
> Students with an opportunity to recieve a voicher scored **.25 standard deviations** higher than students who did not recieve an opportunity to get a voucher.

## Calculating Power

Power calculations are based on the `pwr` package and come from [https://www.statmethods.net/stats/power.html](https://www.statmethods.net/stats/power.html).

```{r}
library(pwr)
```

### New York Scholarship Program (NYSP) Power Analysis

#### T-Tests

The following calculates power from the NYSP t-test example (Strategy 1, Table 4.1, pg. 49)


```{r}
nysp_power <- pwr.t2n.test(n1 = 230, n2= 291, d = .257, sig.level =0.05, power = )
```
```{r echo=FALSE}
tribble(
  ~n1, ~n2, ~d, ~sig, ~power,
   nysp_power[["n1"]], nysp_power[["n2"]], nysp_power[["d"]], nysp_power[["sig.level"]], nysp_power[["power"]]
) %>%
  apa("Power of the NYSP Voucher T-Test")

```

> **Interpretation**
> 
> This is a post-hoc power analysis. The study above had a power of .82. That is, it had an 82% chance to detect and effect if there was once and there was a 18% chance of making a type II error (rejecting a null hypothesis when there is an effect).

#### Simple Linear Regression

Recall Strategy 2, Table 4.1, pg. 49):

```{r}
#model
mm4_model1 <- lm(post_ach ~ voucher, data=nysp_vouchers)
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
apa.reg.table(mm4_model1)[[3]] %>%
  apa("Simple Linear Regression")
apa.aov.table(mm4_model1)[[3]] %>% 
  apa("ANOVA Table for Simple Linear Regresion")
```

##### Power for NYSP Simple Linear Regression

Use `pwr.f2.test(u =, v = , f2 = , sig.level = , power = )` where,

  * u = numerator or *df* of predictors (e.g. number of predictors including each dummy variable)
  * v = denominator or *df* for the residual
  * f2 = Cohen's $f^2$, which is equal to $\frac{R^2}{1-R^2}$

Based on the regression results, the NYSP simple linear regression model had the following power:

```{r}
nysp_regpower <- pwr.f2.test(u = 1, v = 519, f2 = .016/(1-.016), sig.level = .05, power = )
```
```{r echo=FALSE}
tribble(
  ~Predictors, ~"Residual df", ~r2, ~sig, ~power,
   nysp_regpower[["u"]], nysp_regpower[["v"]], nysp_regpower[["f2"]], nysp_regpower[["sig.level"]], nysp_regpower[["power"]]
) %>%
  apa("Power of the NYSP Voucher Simple Linear Regression Test")
```

> **Interpretation**
> 
> Because no covariates were used, the results here are the same as the t-test above.

##### Power for NYSP Multiple Regression

(Strategy 3, Table 4.1, pg 49)

```{r}
mm4_model2 <- lm(post_ach ~ voucher + pre_ach, data = nysp_vouchers)
apa.reg.table(mm4_model2)[[3]] %>% apa()
apa.aov.table(mm4_model2)[[3]] %>% apa()
```


Based on the regression results, the NYSP multiple regression model had the following power:

```{r}
nysp_regpower_2 <- pwr.f2.test(u = 2, v = 518, f2 = .442/(1-.442), sig.level = .05, power = )
```
```{r echo=FALSE}
tribble(
  ~Predictors, ~"Residual df", ~r2, ~sig, ~power,
   nysp_regpower_2[["u"]], nysp_regpower_2[["v"]], nysp_regpower_2[["f2"]], nysp_regpower_2[["sig.level"]], nysp_regpower_2[["power"]]
) %>%
  apa("Power of the NYSP Voucher Multiple Regression Test")
```

> **Interpretation**
> 
> The post-hoc test of power indicated that the large sample size and large $R^2$ had a power of 1, or approximately a 100% chance to detect an effect if there was one.  


## Effect Size Calculator

> Here is a quick interactive calculator I made. It's **very** basic.

```{r}
knitr::include_url('https://acircleda.shinyapps.io/PowerCalculator/', height = '900px')
```


## Accuracy in Parameter Estimation (AIPE)

AIPE is another method which can be used to calculate estimated sample size. It is based on specifying a confidence interval in which you would find an effect size of interest. Here is an example based on the NYSP multiple regression using the `MBESS` package:

```{r message=FALSE, warning=FALSE}
library(MBESS)

ss.aipe.R2(Population.R2 = .442, conf.level = .95, width=.10, p=2, Random.Predictors = FALSE)
```

To find an $R^2$ of .442${_{CI}}_{[.3-.5]}$, you would need the sample size indicated above (661). The actual sample size that found the $R^2$ of .442 was 520. The estimate was not exact, but was very close.

*****

**References**

Kabacoff, R. I. (2017). Power analysis. *Quick-R*. [https://www.statmethods.net/stats/power.html](https://www.statmethods.net/stats/power.html) 

Murnane, R. J., & Willett, J. B. (2010). *Methods matter: Improving causal inference in educational and social science research*. Oxford University Press.
