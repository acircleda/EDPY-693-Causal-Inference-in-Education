# 7. Propensity Score Matching

## Key Concepts

  * Propensity scores can be used as an attempt to deal with treatment bias in non-experimental data.
  * It is more powerful than simply including many covariates because it attempts to minimize observed differences through predictions from logistic regression.

## Methods Matter, Chapter 12

The following example comes from Murnane and Willett (2010), chapter 12.

**NELS-88 Public vs. Catholic School Math Achievement**

"We investigate the impact on a studentâ€™s twelfth-grade mathematics achievement of attending a Catholic (versus a public) high school while attempting to remove bias due to observed differences in base-year family income, parental educational attainment and expectations, and base-year student academic achievement and behavior." This is based on research by Altonji, Elder, and Taber (2005).

The sample contains the 5,671 students from the NELS-88 dataset who were living in families with annual income of less than $75,000 (in 1988 dollars) in the base year of the survey.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# load packages
library(tidyverse)
library(haven)
library(gt)
library(janitor)
library(psych)
library(apaTables)
library(broom)
library(modelsummary)
source("data/apafunction.R")
source("data/apa_msummary.R")
source("data/corstars.R")
```

```{r, message=FALSE, warning=FALSE}
#load and prep data
nels88 <- read_dta("data/methods_matter/ch12_catholic.dta")
```

```{r}
labelled::var_label(nels88) %>%
  unlist() %>%
  matrix(nrow=25, byrow=T) %>% 
  as.data.frame() %>%
  rename("description" = V1) %>%
  add_column(variable = names(nels88), .before=1) %>%
  apa("Key Variables")
  
```

### Descriptive Statistics

```{r message=FALSE, warning=FALSE}
describe(nels88) %>%
  as.data.frame() %>%
  select(n, mean, sd, min, max, skew, kurtosis) %>%
  rownames_to_column("variables") %>%
  slice(3, 6, 17) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  apa("Descriptive statistics for mathematics score (math12), type of high school (catholic), and family income (faminc8)")

nels88 %>%
  mutate(catholic = as_factor(catholic),
         faminc8 = as_factor(faminc8)) %>%
  tabyl(faminc8, catholic) %>%
    adorn_totals(c("row", "col")) %>%
  apa("Catholic school attendance by family income") %>%
  tab_spanner("Attended Catholic school?", vars(no, yes))

nels88 %>%
  tabyl(faminc8, catholic) %>%
  chisq.test()

nels88 %>%
  mutate(faminc8 = as_factor(faminc8),
         catholic = as_factor(catholic)) %>%
  ggplot()+
  coord_flip()+
  geom_point(aes(x=faminc8, y=catholic, color=catholic),
             position = position_jitter())+
  guides(color = guide_legend(reverse=T))+
  labs(title="Distribution of individuals by school type and income")
```

#### Generating Variable Categories

The book examples uses generated variables *faminc8*, which uses the actual mid-values of each income range, scaled.

```{r}
nels88 <- nels88 %>%
  mutate(inc8 = dplyr::recode(faminc8,
    "1" = 0,
    "2"=.5,
    "3"=2,
    "4"=4,
    "5"=6.25,
    "6"=8.75,
    "7"=12.5,
    "8"=17.5,
    "9"=22.5,
    "10"=30,
    "11"=42.5,
    "12"=62.5
  ))
```


### Determining the Best Model

Before generating propensity scores, it is important to determine the best model that predicts group membership through an iterative process.

```{r}

# this functions adds chi-square to model summary outputs
glance_custom.glm <- function(x) {
    lrchi2 <- lmtest::lrtest(x)[2,4]
    lrchi2out <- tibble::tibble(`LR Chi-Square:` = lrchi2)
    return(lrchi2out)
}

nels88_modela <- glm(catholic ~ (inc8*math8),
                     data=nels88, family="binomial")

nels88_modelb <- glm(catholic ~ I(inc8^2) + (inc8*math8),
                     data=nels88, family="binomial")

nels88_modelc <- glm(catholic ~ I(inc8^2) + (inc8*math8) + fhowfar + mhowfar + fight8 + nohw8 + disrupt8 + riskdrop8,
                     data=nels88, family="binomial")

msummary(list(
  "Model A" = nels88_modela, 
  "Model B" = nels88_modelb,
  "Model c" = nels88_modelc)) %>%
  apa_msummary("Parameter estimates and approximate p-values for a set of fitted logistic regression models in which attendance at a public or a Catholic high school (CATHOLIC) has been regressed on hypothesized selection predictors (INC8 and MATH8) that describe the base-year annual family income and student mathematics achievement (n = 5,671)")


```
> **Interpretations**
> 
> Model C was determined to be the best based on having smaller model fit statistics AIC/BIC. Also, since Model B is nested within Model C, we can perform a Likelihood-Ratio Chi-squared test between the model deviances (i.e., $-2\times LL$): $(-2 \times -1833.541) - (-2\times -1804.125) = 58.8$, which is distibuted as a Chi-squared with degrees of freedom equal the difference in the number of paramters between models (10-4 = 6): $\chi^2$(6)=58.8, p < .001. 
>
> Note: a polynomial term ($inc8^2$) to account for a non-linear relationship between catholic and inc8. See Box-Tidwell (i.e., adding interactions between the continuous variables and its natural log, if it's significant, it suggest non-linearity) and link tests (i.e., this uses the predicted values and square of predicted values to test whether the model is properly specified, the squared term should not be statistically significant) for logistic regression. 

### Examining the Region of Common Support

These graphics show the overlap of the propensity scores of the two groups, suggesting they share a lot of common support on the covariates in the model. Common support indicates the regions of stratification share enough members of the treatment and control groups.


```{r}

# Create Propensity Scores
nels88_propscore <- data.frame(pr_score = predict(nels88_modelc,
                                  type="response")) %>%
  add_column(nels88_modelc$data)

nels88_propscore %>%
  mutate(catholic = ifelse(catholic == 1, "Catholic", "Public")) %>%
  ggplot()+
  geom_histogram(aes(x=pr_score, y=..density..,), color="white", bins=30)+
  geom_density(aes(x=pr_score))+
  facet_wrap(~catholic, ncol=1)

nels88_propscore %>%
  mutate(catholic = ifelse(catholic == 1, "Catholic", "Public")) %>%
  ggplot()+
  geom_histogram(aes(x=pr_score, y=..density.., fill=catholic), color="white", bins=30, position="identity", alpha=.3)+
  geom_density(aes(x=pr_score, color=catholic))
```

### Stratifying on the Propensities

#### Stratification into 5 blocks based on quintiles

```{r}
# making quintiles
nels88_5blocks <- nels88_propscore %>%
  mutate(blocks = ntile(pr_score, 5),
         catholic = factor(catholic, labels = c(
           "Catholic", "Public"
         ))) %>%
  group_by(blocks)
```

#### Checking balance on the propensities
```{r}
do(nels88_5blocks, tidy(t.test(.$pr_score ~ .$catholic,
                 alternative = "greater",
                 paired = FALSE,
                 var.equal = TRUE,
                 conf.level = 0.95
                 ))) %>%
  select(blocks, p.value) %>%
  ungroup() %>%
  apa("Testing balance of blocks based on quntiles")
```

> **Interpretation**
>
> The table above shows t-tests per block between propensity scores and treatment groups. Using a one-sided test where the expectation is a greater score, none of the differences are significant. This suggests balance. 
>
> Note: if you choose "less", you will get different results becuase it is the lower side of the one-sided t-test. You'd be testing whether the expectation is a lower score. You may also want to check individual covariate balance, as below. 

#### Stratification into 5 blocks based on cut scores

The following stratification comes from p. 320
```{r warning=FALSE}

nels88_5blocks_2 <- nels88_propscore %>%
  mutate(blocks = case_when(
    pr_score < .05 ~ 1,
    pr_score = .05 & pr_score <.1 ~2,
    pr_score =.1 & pr_score <.15 ~ 3,
    pr_score = .15 & pr_score < .2 ~ 4,
    pr_score = .2 & pr_score < .3 ~ 5
  ),
  catholic = factor(catholic, labels = c(
           "Public", "Catholic"
         ))) %>%
  group_by(blocks)

do(nels88_5blocks_2, tidy(t.test(.$pr_score ~ .$catholic,
                 alternative = "greater",
                 paired = FALSE,
                 var.equal = TRUE,
                 conf.level = 0.95
                 ))) %>%
  select(blocks, p.value) %>%
  ungroup() %>%
  apa("Testing balance of blocks based on the book's example")

```

#### Estimate the ATE and ATT of Stratified Propensity Scores

```{r}

# Summarize Block
nels88_5blocks_sum <- nels88_5blocks_2 %>%
  group_by(blocks, catholic) %>%
  summarize(n = n(),
    pr_score = mean(pr_score),
            income_mean=mean(inc8),
            mathmean = mean(math8),
            math_achievment = mean(math12)) %>%
  pivot_wider(names_from=catholic, values_from = c(n, pr_score, income_mean, mathmean, math_achievment)) %>%
  mutate(diff = math_achievment_Catholic - math_achievment_Public,
         n = n_Catholic + n_Public,
         mutate(across(where(is.numeric), round, 3))) %>%
  ungroup()

apa(nels88_5blocks_sum, "Five propensity-score blocks, based on predicted values from final Model C (which contains selected covariates in addition to those included in Model B). Within-block sample statistics include: (a) frequencies, (b) average propensity scores, and (c) average twelfth grade mathematics achievement by type of high school, and their difference (n = 5,671)")

#Weighted Average Treatment Effect
nels88_5blocks_sum %>%
  mutate(weighted = diff * n) %>%
  pull(weighted) %>%
  sum()/sum(nels88_5blocks_sum$n)

#Weighted Average Treatment on the Treated Effect
nels88_5blocks_sum %>%
  mutate(weighted = diff * n_Catholic) %>%
  pull(weighted) %>%
  sum()/sum(nels88_5blocks_sum$n_Catholic)

```



### Using MatchIt

Method from [http://www.practicalpropensityscore.com/matching.html](http://www.practicalpropensityscore.com/matching.html)

```{r message=FALSE, warning=FALSE}
library(MatchIt)

set.seed(2020)

#generate propensity scores using Model C
nels88_ps <- matchit(catholic ~ I(inc8^2) + (inc8*math8) + fhowfar + mhowfar + fight8 + nohw8 + disrupt8 + riskdrop8,
                         data=nels88,
                         method="nearest", #nearest neighbors
                         replace=T, #with replacement
                        ratio=1) #one to one matching - each treated with one control
                    
                    #A user may want to consider adding a caliper option to only select cases within a certain range, caliper = .2
       
```


#### Diagnose Covariate Balance

```{r}
nels88_ps_sum <- summary(nels88_ps)

#raw
#summary(abs(nels88_ps_sum$sum.matched$`Mean Diff`))
```

This table shows the maximum standardized mean difference in propensity scores ? between groups.

```{r}
summary(abs(summary(nels88_ps, standardize = T)$sum.matched$`Std. Mean Diff`))
```
> The results show Small differences between groups on the covariates.  (Max = .05).


```{r}
table(abs(summary(nels88_ps, standardize = T)$sum.matched$"Std. Mean Diff.") > .1) #Table says Max = .05, but this function says there are 11 cases with Std.Mean.Diff > .1

```
> This table shows that only there are no differences greater than .1 (FALSE 11)

#### Estimate Treatment Effects

```{r message=FALSE, warning=FALSE}
#obtain matched data
matched_data <- match.data(nels88_ps)

# use weights to estimate ATT
library(survey)
design.nels88 <- svydesign(ids=~1, weights=~weights,
                                   data=matched_data)
#estimate the ATT 
model.nels88 <- svyglm(math12~catholic + I(inc8^2) + (inc8*math8) + fhowfar + mhowfar + fight8 + nohw8 + disrupt8 + riskdrop8, design.nels88, family=gaussian())

summary(model.nels88)
```

> Because of unmatched controls (4,546; see `summary(nels88_ps)`), we can typically only estimate the ATT since we don't typically include the entire sample. Weighting by the inverse of the propensity score then running the analysis is one way to get the ATE. You can also get ATE from stratification. 


### Another MatchIt Method 

From [Propensity Scores:	A Practical Introduction Using R](https://journals.sfu.ca/jmde/index.php/jmde_1/article/view/431)

#### Visualize Propensity Scores

```{r message=FALSE, warning=FALSE}
plot(nels88_ps, type ="jitter")
```

#### Prepare Matched Data
```{r}
# save matched data
matches <- data.frame(nels88_ps$match.matrix)

# find the  matches
group1 <- match(row.names(matches), row.names(matched_data))
group2 <- match(matches$X1, row.names(matched_data))

# extract outcome values for matches
treatment <- matched_data$math12[group1]
control <- matched_data$math12[group2]

# create matched data set
outcomes <- cbind(matches, treatment, control)

# t-test
t.test(outcomes$treatment, outcomes$control, paired = T) %>% 
  tidy() %>%
  select(estimate:p.value, method, alternative) %>%
  apa("Outcome Analysis")

```
> .93 is the ATT. It is lower than what's found in the *Methods Matter*, but it also uses a slightly different method. One thing we'd want to do is assess the robustness of these results by altering parameters of the matching algorithm (e.g., adding a caliper, altering the values of the caliper .2 to .15, matching with and without replacement, ratio matching 1:5) or by choosing a different matching algorithm (e.g., optimal matching, full matching). These type of tests help demonstrate that results do not depend on the particular matching method chosen.

### Stratification with MatchIt

Based on *Practical Propensity Score Methods Using R* (Leite, 2019)

```{r}

formula <- formula("catholic ~ I(inc8^2) + (inc8*math8) + fhowfar + mhowfar + fight8 + nohw8 + disrupt8 + riskdrop8")

# make the subclasses
nels_stratified <- matchit(formula, #formula
                          distance=nels88_propscore$pr_score, #propensity scores
                          data = nels88_propscore, #data
                          method = "subclass", #statifying method
                          sub.by = "treat",
                          subclass=5) # quintiles

# get the matched data
data.stratification <- match.data(nels_stratified) %>%
  mutate(catholic = factor(catholic, labels=c("Public", "Catholic")))
  
#preview
data.stratification %>%
  janitor::tabyl(catholic, subclass)
```

#### Covariate Balance Evaluation

```{r}
# obtain standardize mean differences
balance.stratification <- summary(nels_stratified, standardize=T)

# the following extracts only the standardized mean differences for all strata
balance.stratification$q.table[,3,] %>%
  as.data.frame() %>%
  pivot_longer("Subclass 1":"Subclass 5", names_to = "strata", values_to="mean_diff") %>%
  group_by(strata) %>%
  summarize(min = min(mean_diff),
            mean = mean(mean_diff),
            max = max(mean_diff))
```

> Two stratas have greater than .1 and 1 has greater than .25. This is OK, but not great.

#### Obtaining ATE and ATE Estimates

```{r}
design <- svydesign(ids=~0, 
                    weights=~weights,
                    data=data.stratification)

# Robust SE through bootstrapping
# Good for when not known or easy formula

set.seed(2020)

surveyDesignBoot <- as.svrepdesign(design, type=c("bootstrap"),replicates=1000)

#obtain means and standard errors by stratum and treatment group combinations

subclassMeans <- svyby(formula=~math12, 
                        by=~catholic+subclass,
                        design=surveyDesignBoot,
                        FUN=svymean,
                       covmat=TRUE)

# get weights for estimation

weights <- data.stratification %>%
  janitor::tabyl(catholic, subclass) %>%
  pivot_longer(`1`:`5`, names_to = "strat", values_to = "n") %>%
  pivot_wider(names_from = catholic, values_from=n) %>%
  mutate(strat_sum = Public + Catholic,
         total_treated = sum(Catholic),
         total_n = sum(strat_sum),
         ATE_wk = strat_sum/total_n,
         ATT_wk = Catholic/total_treated)

# estimation via linear/nonlinear contrasts
pooledEffects <- svycontrast(subclassMeans, list(
    ATE=c(rbind(-weights$ATE_wk, weights$ATE_wk)),
    ATT=c(rbind(-weights$ATT_wk, weights$ATT_wk))))

pooledEffects
```

> Is it significant?